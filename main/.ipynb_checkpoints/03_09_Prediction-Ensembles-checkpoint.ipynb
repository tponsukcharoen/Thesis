{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "import patsy #for spline regression\n",
    "import scipy #for non-negative least square \n",
    "import scipy as sp \n",
    "from scipy import stats\n",
    "from scipy.optimize import nnls\n",
    "from numpy.linalg import inv #for matrix and statistics\n",
    "import scipy as sp\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.cluster\n",
    "import sklearn.linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sklearn.cluster\n",
    "import sklearn.linear_model\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.svm import SVR\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#specify data source \n",
    "datasource = 'LocusEnergy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipcode = '92562'\n",
    "#zipcode = '08641'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mainDir = 'C:/Users/umnouyp/Dropbox/Active/EnergyProject/Thesis/PVreadingsStudies/main'\n",
    "#mainDir = 'C:/Users/Tee/Dropbox/Active/EnergyProject/Thesis/PVreadingsStudies/main'\n",
    "mainDir = 'C:\\Users\\Admin\\Dropbox\\Active\\EnergyProject\\Thesis\\PVreadingsStudies\\main'\n",
    "#we can choose which data to look at.\n",
    "dataDir = mainDir + '/data/' + datasource +'/' + zipcode +'/'\n",
    "outputDir = mainDir + '/output/'+ datasource +'/' + zipcode +'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataDir +'/training_data_fitted_adjusted.csv')\n",
    "data['tsLocal'] = data['tsLocal'].map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "dsummary = pd.read_csv(outputDir+\"/fitsummary.csv\")\n",
    "dsummary.Date = dsummary.Date.map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "FullModelCoef = pd.read_csv(outputDir+\"/FullModelCoef.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weatherdatasource = '/data/Weather/weathersource/hourly/'\n",
    "if (zipcode == '08641')|(zipcode =='08640'):\n",
    "    weatherdata = pd.read_csv(mainDir+weatherdatasource+'08641_20132014.csv')\n",
    "if (zipcode == '92562')|(zipcode =='92563'):\n",
    "    weatherdata = pd.read_csv(mainDir+weatherdatasource+'92563_20132014.csv')\n",
    "\n",
    "weatherdata['tsLocal'] = weatherdata.timestamp.map(lambda x: x[0:10] + \" \" + x[11:19])\n",
    "#weatherdata.tsLocal = weatherdata.tsLocal.map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "if type(weatherdata.tsLocal[0])==str:\n",
    "    weatherdata['tsLocal'] = weatherdata['tsLocal'].map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "weatherdata.drop(['timestamp','country','postal_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if weatherdata.shape[0]!=len(set(weatherdata['tsLocal'])):\n",
    "    for i in range(weatherdata.shape[0]):\n",
    "        if weatherdata.loc[i,'tsLocal'] == weatherdata.loc[(i+1),'tsLocal']:\n",
    "            print weatherdata.loc[i,'tsLocal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>Rsq</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>c10</th>\n",
       "      <th>Date</th>\n",
       "      <th>DBW</th>\n",
       "      <th>singlemax</th>\n",
       "      <th>PeakCheck</th>\n",
       "      <th>FirstCheck</th>\n",
       "      <th>SecondCheck</th>\n",
       "      <th>mE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 2013-01-01</td>\n",
       "      <td>-355</td>\n",
       "      <td>NaN</td>\n",
       "      <td> False</td>\n",
       "      <td> False</td>\n",
       "      <td> False</td>\n",
       "      <td> 5.120855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    E  Rsq  c0  c1  c2  c3  c4  c5  c6  c7  c8  c9  c10        Date  DBW  \\\n",
       "0 NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  2013-01-01 -355   \n",
       "\n",
       "   singlemax PeakCheck FirstCheck SecondCheck        mE  \n",
       "0        NaN     False      False       False  5.120855  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsummary[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBW</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>c10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0.177334</td>\n",
       "      <td> 0.467511</td>\n",
       "      <td> 0.568511</td>\n",
       "      <td> 0.710033</td>\n",
       "      <td> 0.746246</td>\n",
       "      <td> 0.75671</td>\n",
       "      <td> 0.714601</td>\n",
       "      <td> 0.677578</td>\n",
       "      <td> 0.527082</td>\n",
       "      <td> 0.429756</td>\n",
       "      <td> 0.149853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DBW        c0        c1        c2        c3        c4       c5        c6  \\\n",
       "0    0  0.177334  0.467511  0.568511  0.710033  0.746246  0.75671  0.714601   \n",
       "\n",
       "         c7        c8        c9       c10  \n",
       "0  0.677578  0.527082  0.429756  0.149853  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FullModelCoef[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsLocal</th>\n",
       "      <th>altitude</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>power</th>\n",
       "      <th>numactivecomp</th>\n",
       "      <th>totalsize</th>\n",
       "      <th>s</th>\n",
       "      <th>DBW</th>\n",
       "      <th>mpower</th>\n",
       "      <th>r</th>\n",
       "      <th>expectedr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 07:00:00</td>\n",
       "      <td> 0.772319</td>\n",
       "      <td>-298.174761</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 2</td>\n",
       "      <td> 13.528266</td>\n",
       "      <td>-0.999883</td>\n",
       "      <td>-355</td>\n",
       "      <td> 0.264652</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 0.706748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tsLocal  altitude     azimuth  power  numactivecomp  totalsize  \\\n",
       "0 2013-01-01 07:00:00  0.772319 -298.174761    NaN              2  13.528266   \n",
       "\n",
       "          s  DBW    mpower   r  expectedr  \n",
       "0 -0.999883 -355  0.264652 NaN   0.706748  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic time series construction with hourly volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct time series of power and power ratio. We add time without sun to create consistent time series. In addition, we add parallel values of previous 15 minute instances (-1, -2, ...) and previous day instances (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#specify scope\n",
    "StartScopeDate = '2013-01-01'\n",
    "EndScopeDate = '2015-01-01'\n",
    "StartScopeTime =  datetime.datetime.strptime(StartScopeDate,\"%Y-%m-%d\")\n",
    "EndScopeTime =  datetime.datetime.strptime(EndScopeDate,\"%Y-%m-%d\")\n",
    "\n",
    "#Generate data frame from start to end for time series\n",
    "tslist = []\n",
    "nxt = StartScopeTime\n",
    "while nxt < EndScopeTime:\n",
    "    tslist.append(nxt)\n",
    "    nxt += datetime.timedelta(minutes=15)\n",
    "        \n",
    "Scope = pd.DataFrame(0, index = np.arange(len(tslist)), columns = ['tsLocal'])\n",
    "Scope['tsLocal'] = tslist\n",
    "\n",
    "#Now we can merge using Scope Table as a backbone of data structure.\n",
    "d = pd.merge(Scope,weatherdata,on=['tsLocal'], how = 'left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70080, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(1,12):\n",
    "    for i in range(0,d.shape[0]/4-1):\n",
    "        if (type(d.iloc[4*i,j])!=pd.tslib.NaTType) & (type(d.iloc[4*(i+1),j])!=pd.tslib.NaTType):\n",
    "        #d.iloc[4*(i+1),1]=float('NaN')\n",
    "            d.iloc[4*i+1,j] = 0.75*d.iloc[4*i,j]+0.25*d.iloc[4*(i+1),j]\n",
    "            d.iloc[4*i+2,j] = 0.50*d.iloc[4*i,j]+0.50*d.iloc[4*(i+1),j]\n",
    "            d.iloc[4*i+3,j] = 0.25*d.iloc[4*i,j]+0.75*d.iloc[4*(i+1),j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we can merge our backbone + weather with solar data\n",
    "d = pd.merge(d,data,on=['tsLocal'], how = 'left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#timeseries of previous timestamps\n",
    "d['power-1'] = float('NaN')\n",
    "d['mpower-1'] = float('NaN')\n",
    "d['mpower-2'] = float('NaN')\n",
    "d['mpower-3'] = float('NaN')\n",
    "d['mpower-4'] = float('NaN')\n",
    "d['power-2'] = float('NaN')\n",
    "d['power-3'] = float('NaN')\n",
    "d['power-4'] = float('NaN')\n",
    "d['power-5'] = float('NaN')\n",
    "d['power-6'] = float('NaN')\n",
    "d['power_y-0'] = float('NaN')\n",
    "d['power_y-1'] = float('NaN')\n",
    "d['power_y-2'] = float('NaN')\n",
    "d['r-1'] = float('NaN')\n",
    "d['r-2'] = float('NaN')\n",
    "d['r-3'] = float('NaN')\n",
    "d['r-4'] = float('NaN')\n",
    "d['r-5'] = float('NaN')\n",
    "d['r-6'] = float('NaN')\n",
    "d['r_y-0'] = float('NaN')\n",
    "d['r_y-1'] = float('NaN')\n",
    "d['r_y-2'] = float('NaN')\n",
    "d.loc[1:d.shape[0],'r-1'] = list(d['r'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[2:d.shape[0],'r-2'] = list(d['r'].iloc[0:(d.shape[0]-2)])\n",
    "d.loc[3:d.shape[0],'r-3'] = list(d['r'].iloc[0:(d.shape[0]-3)])\n",
    "d.loc[4:d.shape[0],'r-4'] = list(d['r'].iloc[0:(d.shape[0]-4)])\n",
    "d.loc[5:d.shape[0],'r-5'] = list(d['r'].iloc[0:(d.shape[0]-5)])\n",
    "d.loc[6:d.shape[0],'r-6'] = list(d['r'].iloc[0:(d.shape[0]-6)])\n",
    "d.loc[1:d.shape[0],'mpower-1'] = list(d['mpower'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[2:d.shape[0],'mpower-2'] = list(d['mpower'].iloc[0:(d.shape[0]-2)])\n",
    "d.loc[3:d.shape[0],'mpower-3'] = list(d['mpower'].iloc[0:(d.shape[0]-3)])\n",
    "d.loc[4:d.shape[0],'mpower-4'] = list(d['mpower'].iloc[0:(d.shape[0]-4)])\n",
    "d.loc[1:d.shape[0],'power-1'] = list(d['power'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[2:d.shape[0],'power-2'] = list(d['power'].iloc[0:(d.shape[0]-2)])\n",
    "d.loc[3:d.shape[0],'power-3'] = list(d['power'].iloc[0:(d.shape[0]-3)])\n",
    "d.loc[4:d.shape[0],'power-4'] = list(d['power'].iloc[0:(d.shape[0]-4)])\n",
    "d.loc[5:d.shape[0],'power-5'] = list(d['power'].iloc[0:(d.shape[0]-5)])\n",
    "d.loc[6:d.shape[0],'power-6'] = list(d['power'].iloc[0:(d.shape[0]-6)])\n",
    "\n",
    "#24 hour shift = 24*4 shift in index. 'y' means yesterday\n",
    "d.loc[96:d.shape[0],'r_y-0'] = list(d['r'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'r_y-1'] = list(d['r-1'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'r_y-2'] = list(d['r-2'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'r_y-3'] = list(d['r-3'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'r_y-4'] = list(d['r-4'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'power_y-0'] = list(d['power'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'power_y-1'] = list(d['power-1'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'power_y-2'] = list(d['power-2'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'power_y-3'] = list(d['power-3'].iloc[0:(d.shape[0]-96)])\n",
    "d.loc[96:d.shape[0],'power_y-4'] = list(d['power-4'].iloc[0:(d.shape[0]-96)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['cldCvr-1'] = float('NaN')\n",
    "d['dewPt-1'] = float('NaN')\n",
    "d['feelsLike-1'] = float('NaN')\n",
    "d['precip-1'] = float('NaN')\n",
    "d['relHum-1'] = float('NaN')\n",
    "d['sfcPres-1'] = float('NaN')\n",
    "d['snowfall-1'] = float('NaN')\n",
    "d['spcHum-1'] = float('NaN')\n",
    "d['temp-1'] = float('NaN')\n",
    "d['windSpd-1'] = float('NaN')\n",
    "d['wetBulb-1'] = float('NaN')\n",
    "d.loc[1:d.shape[0],'cldCvr-1'] = list(d['cldCvr'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'dewPt-1'] = list(d['dewPt'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'feelsLike-1'] = list(d['feelsLike'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'precip-1'] = list(d['precip'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'relHum-1'] = list(d['relHum'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'sfcPres-1'] = list(d['sfcPres'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'snowfall-1'] = list(d['snowfall'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'spcHum-1'] = list(d['spcHum'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'temp-1'] = list(d['temp'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'windSpd-1'] = list(d['windSpd'].iloc[0:(d.shape[0]-1)])\n",
    "d.loc[1:d.shape[0],'wetBulb-1'] = list(d['wetBulb'].iloc[0:(d.shape[0]-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize weather value\n",
    "d['cldCvr-1'] = (d['cldCvr-1']-np.min(d['cldCvr-1']))/(np.max(d['cldCvr-1'])-np.min(d['cldCvr-1']))\n",
    "d['dewPt-1'] = (d['dewPt-1']-np.min(d['dewPt-1']))/(np.max(d['dewPt-1'])-np.min(d['dewPt-1']))\n",
    "d['feelsLike-1'] = (d['feelsLike-1']-np.min(d['feelsLike-1']))/(np.max(d['feelsLike-1'])-np.min(d['feelsLike-1']))\n",
    "d['precip-1'] = (d['precip-1']-np.min(d['precip-1']))/(np.max(d['precip-1'])-np.min(d['precip-1']))\n",
    "d['relHum-1'] = (d['relHum-1']-np.min(d['relHum-1']))/(np.max(d['relHum-1'])-np.min(d['relHum-1']))\n",
    "d['sfcPres-1'] = (d['sfcPres-1']-np.min(d['sfcPres-1']))/(np.max(d['sfcPres-1'])-np.min(d['sfcPres-1']))\n",
    "d['snowfall-1'] = (d['snowfall-1']-np.min(d['snowfall-1']))/(np.max(d['snowfall-1'])-np.min(d['snowfall-1']))\n",
    "d['spcHum-1'] = (d['spcHum-1']-np.min(d['spcHum-1']))/(np.max(d['spcHum-1'])-np.min(d['spcHum-1']))\n",
    "d['temp-1'] = (d['temp-1']-np.min(d['temp-1']))/(np.max(d['temp-1'])-np.min(d['temp-1']))\n",
    "d['windSpd-1'] = (d['windSpd-1']-np.min(d['windSpd-1']))/(np.max(d['windSpd-1'])-np.min(d['windSpd-1']))\n",
    "d['wetBulb-1'] = (d['wetBulb-1']-np.min(d['wetBulb-1']))/(np.max(d['wetBulb-1'])-np.min(d['wetBulb-1']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute rolling hourly volaitility (this is for 15 min interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#volatility derivative-based and persistence-based\n",
    "#d['V-d'] = np.absolute(d['power-1']-4*d['power-2']+6*d['power-3']-4*d['power-4']+d['power-5'])\n",
    "d['V-s'] = np.absolute(d['power-1']-d['power-2']/d['mpower-2']*d['mpower-1'])+\\\n",
    "            np.absolute(d['power-2']-d['power-3']/d['mpower-3']*d['mpower-2'])+\\\n",
    "             np.absolute(d['power-3']-d['power-4']/d['mpower-4']*d['mpower-3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we separate data for training and testing. Need this for autoregressive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data = d\n",
    "#select data for training and test\n",
    "StartDate = datetime.date(2014,10,1)\n",
    "TrainData = d[d.tsLocal.map(lambda x: x.date()) <StartDate].set_index('tsLocal')\n",
    "TrainDateList = list(dsummary.Date[dsummary.Date<StartDate])\n",
    "TestData = d[d.tsLocal.map(lambda x: x.date()) >=StartDate].set_index('tsLocal')\n",
    "\n",
    "#Extra screening by high energy days\n",
    "HighEnergyDayList = list(dsummary.Date[dsummary.E/dsummary.mE>0.9]) #for NJ\n",
    "HighEnergyTestData = d[d.tsLocal.map(lambda x: (x.date()>=StartDate) & (x.date() in HighEnergyDayList))].set_index('tsLocal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#15-minute rolling prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any model, make a consistent train/test by randomly assign 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = Data\n",
    "#Truly random\n",
    "#l = np.random.permutation(d.shape[0])\n",
    "#d = d.iloc[l].reset_index(drop=True)\n",
    "#offset = int(d.shape[0] * 0.8)\n",
    "\n",
    "#Assign specific period\n",
    "StartDate = datetime.date(2014,10,1)\n",
    "offset = d[d.tsLocal.map(lambda x: x.date()) <StartDate].shape[0]\n",
    "\n",
    "Data_train = d[:offset]\n",
    "Data_test = d[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For bin reference\n",
    "numbins = int(math.ceil(np.max(d['V-s'])/0.1))\n",
    "meandifflist = [0]*numbins\n",
    "maxdifflist = [0]*numbins\n",
    "middlebinvalue = [0.1*i+0.05 for i in range(0,numbins)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for zeroth method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['power_predict_zeroth'] = float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = ['expectedr']\n",
    "\n",
    "DateOfInterest = StartDate \n",
    "\n",
    "while DateOfInterest < EndScopeTime.date():\n",
    "#if(1==1):\n",
    "    \n",
    "    #print(DateOfInterest)\n",
    "\n",
    "    d_imm = Data.loc[:,['tsLocal','power','mpower','r']+feature_names].dropna()\n",
    "\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()==DateOfInterest)]\n",
    "\n",
    "    d['power_predict'] = d.loc[:,'expectedr']*d.loc[:,'mpower']\n",
    "    d['power_predict'] = d['power_predict']*(d['power_predict']<d['mpower'])+d['mpower']*(d['power_predict']>=d['mpower'])\n",
    "    d['power_predict'] = 0*(d['power_predict']<0)+d['power_predict']*(d['power_predict']>=0)\n",
    "\n",
    "    #add it into Data\n",
    "    Data.loc[d.index,'power_predict_zeroth'] = d['power_predict']\n",
    "    #update date\n",
    "    DateOfInterest = DateOfInterest + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Data['power_predict_zeroth'].dropna())/90. #number of training points per day "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prediction for GBR with set II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GBR\n",
    "params = {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 1,\n",
    "          'learning_rate': 0.05, 'loss': 'lad'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['power_predict_GBR_set2'] = float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = ['r-1']\n",
    "feature_names = feature_names + ['s','DBW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DateOfInterest = StartDate \n",
    "\n",
    "while DateOfInterest < EndScopeTime.date():\n",
    "    \n",
    "    #print(DateOfInterest)\n",
    "    \n",
    "    d_imm = Data.loc[:,['tsLocal','power','mpower','r']+feature_names].dropna()\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()<DateOfInterest)]\n",
    "    X_train, y_train = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()==DateOfInterest)]\n",
    "    X_test, y_test = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    d['power_predict'] = (clf.predict(X_test))*d.loc[:,'mpower']\n",
    "    d['power_predict'] = d['power_predict']*(d['power_predict']<d['mpower'])+d['mpower']*(d['power_predict']>=d['mpower'])\n",
    "    d['power_predict'] = 0*(d['power_predict']<0)+d['power_predict']*(d['power_predict']>=0)\n",
    "\n",
    "    #add it into Data\n",
    "    Data.loc[d.index,'power_predict_GBR_set2'] = d['power_predict']\n",
    "    #update date\n",
    "    DateOfInterest = DateOfInterest + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Data['power_predict_GBR_set2'].dropna())/90. #number of training points per day "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for GBR with set III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['power_predict_GBR_set3'] = float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = ['r-1']\n",
    "feature_names = feature_names + ['s','DBW']\n",
    "feature_names = feature_names + ['V-s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DateOfInterest = StartDate \n",
    "\n",
    "while DateOfInterest < EndScopeTime.date():\n",
    "    \n",
    "    #print(DateOfInterest)\n",
    "    \n",
    "    d_imm = Data.loc[:,['tsLocal','power','mpower','r']+feature_names].dropna()\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()<DateOfInterest)]\n",
    "    X_train, y_train = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()==DateOfInterest)]\n",
    "    X_test, y_test = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    d['power_predict'] = (clf.predict(X_test))*d.loc[:,'mpower']\n",
    "    d['power_predict'] = d['power_predict']*(d['power_predict']<d['mpower'])+d['mpower']*(d['power_predict']>=d['mpower'])\n",
    "    d['power_predict'] = 0*(d['power_predict']<0)+d['power_predict']*(d['power_predict']>=0)\n",
    "\n",
    "    #add it into Data\n",
    "    Data.loc[d.index,'power_predict_GBR_set3'] = d['power_predict']\n",
    "    #update date\n",
    "    DateOfInterest = DateOfInterest + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Data['power_predict_GBR_set3'].dropna())/90. #number of training points per day "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for GBR with set IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['power_predict_GBR_set4'] = float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['r-1']\n",
    "feature_names = feature_names + ['s','DBW']\n",
    "feature_names = feature_names +['cldCvr-1','dewPt-1','feelsLike-1','precip-1','relHum-1','sfcPres-1','snowfall-1',\n",
    "                        'spcHum-1','temp-1','windSpd-1','wetBulb-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DateOfInterest = StartDate \n",
    "\n",
    "while DateOfInterest < EndScopeTime.date():\n",
    "    \n",
    "    #print(DateOfInterest)\n",
    "    \n",
    "    d_imm = Data.loc[:,['tsLocal','power','mpower','r']+feature_names].dropna()\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()<DateOfInterest)]\n",
    "    X_train, y_train = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()==DateOfInterest)]\n",
    "    X_test, y_test = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    d['power_predict'] = (clf.predict(X_test))*d.loc[:,'mpower']\n",
    "    d['power_predict'] = d['power_predict']*(d['power_predict']<d['mpower'])+d['mpower']*(d['power_predict']>=d['mpower'])\n",
    "    d['power_predict'] = 0*(d['power_predict']<0)+d['power_predict']*(d['power_predict']>=0)\n",
    "\n",
    "    #add it into Data\n",
    "    Data.loc[d.index,'power_predict_GBR_set4'] = d['power_predict']\n",
    "    #update date\n",
    "    DateOfInterest = DateOfInterest + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Data['power_predict_GBR_set4'].dropna())/90. #number of training points per day "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction for GBR with set V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data['power_predict_GBR_set5'] = float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = ['r-1']\n",
    "feature_names = feature_names + ['s','DBW']\n",
    "feature_names = feature_names + ['V-s']\n",
    "feature_names = feature_names +['cldCvr-1','dewPt-1','feelsLike-1','precip-1','relHum-1','sfcPres-1','snowfall-1',\n",
    "                        'spcHum-1','temp-1','windSpd-1','wetBulb-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DateOfInterest = StartDate \n",
    "\n",
    "while DateOfInterest < EndScopeTime.date():\n",
    "    \n",
    "    #print(DateOfInterest)\n",
    "    \n",
    "    d_imm = Data.loc[:,['tsLocal','power','mpower','r']+feature_names].dropna()\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()<DateOfInterest)]\n",
    "    X_train, y_train = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    d = d_imm[d_imm['tsLocal'].map(lambda x: x.date()==DateOfInterest)]\n",
    "    X_test, y_test = d.loc[:,feature_names], d.loc[:,'r']\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    d['power_predict'] = (clf.predict(X_test))*d.loc[:,'mpower']\n",
    "    d['power_predict'] = d['power_predict']*(d['power_predict']<d['mpower'])+d['mpower']*(d['power_predict']>=d['mpower'])\n",
    "    d['power_predict'] = 0*(d['power_predict']<0)+d['power_predict']*(d['power_predict']>=0)\n",
    "\n",
    "    #add it into Data\n",
    "    Data.loc[d.index,'power_predict_GBR_set5'] = d['power_predict']\n",
    "    #update date\n",
    "    DateOfInterest = DateOfInterest + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Data['power_predict_GBR_set5'].dropna())/90. #number of training points per day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1  = fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(middlebinvalue,maxdifflist_zeroth,color='red',label='max_zeroth',linestyle='--')\n",
    "ax1.plot(middlebinvalue,meandifflist_zeroth,color='blue',label = 'mean_zeroth',linestyle='--')\n",
    "ax1.plot(middlebinvalue,maxdifflist_persistent,color='red',label='max_persistent',linestyle=':')\n",
    "ax1.plot(middlebinvalue,meandifflist_persistent,color='blue',label = 'mean_persistent',linestyle=':')\n",
    "ax1.plot(middlebinvalue,maxdifflist_GBR,color='red',label='max_GBR')\n",
    "ax1.plot(middlebinvalue,meandifflist_GBR,color='blue',label = 'mean_GBR')\n",
    "#ax1.plot(df.tsLocal.map(lambda x: x.time()),df.expectedr*df.mpower,color='green')\n",
    "ax1.set_xlabel('volatiliy of the most recent hour')\n",
    "ax1.set_ylabel('prediction difference')\n",
    "ax1.set_ylim(0,0.7)\n",
    "ax1.legend()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data['power_predict_final'] = float('NaN')\n",
    "if zipcode == '92562':\n",
    "    #background prediction\n",
    "    Data['power_predict_final'] = Data['power_predict_zeroth']\n",
    "    \n",
    "    d = Data.loc[:,['power_predict_GBR_set2']].dropna()\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_GBR_set2']\n",
    "    \n",
    "    d = Data.loc[:,['power_predict_GBR_set3']].dropna()\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_GBR_set3']\n",
    "    \n",
    "    #against high volatility\n",
    "    d = Data.loc[:,['V-s','power_predict_zeroth']].dropna()\n",
    "    d = d[d['V-s']>0.6]\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_zeroth']\n",
    "    \n",
    "if zipcode == '08641':\n",
    "    #background prediction\n",
    "    Data['power_predict_final'] = Data['power_predict_zeroth']\n",
    "    \n",
    "    d = Data.loc[:,['power_predict_GBR_set2']].dropna()\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_GBR_set2']\n",
    "    \n",
    "    d = Data.loc[:,['power_predict_GBR_set3']].dropna()\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_GBR_set3']\n",
    "    \n",
    "    d = Data.loc[:,['power_predict_GBR_set4']].dropna()\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_GBR_set4']\n",
    "    \n",
    "    d = Data.loc[:,['power_predict_GBR_set5']].dropna()\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_GBR_set5']\n",
    "    \n",
    "    #against high volatility\n",
    "    d = Data.loc[:,['V-s','power_predict_zeroth']].dropna()\n",
    "    d = d[d['V-s']>0.6]\n",
    "    Data.loc[d.index,'power_predict_final'] = d['power_predict_zeroth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1  = fig.add_subplot(111)\n",
    "#Overall distribution\n",
    "\n",
    "l = list((Data['power_predict_final']-Data['power']).dropna())\n",
    "\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax1.hist(l, 60, normed=1, alpha=0.75)\n",
    "\n",
    "# best fit of data with normal distribution\n",
    "(mu, sigma) = norm.fit(l)\n",
    "print mu, sigma\n",
    "\n",
    "plt.xlabel(\"Predicted value - Actual value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = mlab.normpdf( bins, mu, sigma)\n",
    "ax1.plot(bins, y, 'r--', linewidth=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "laplace = stats.laplace\n",
    "\n",
    "# fit\n",
    "param = laplace.fit(l)\n",
    "x = np.linspace(np.min(l), np.max(l), 100)\n",
    "pdf_fitted = laplace.pdf(x, *param)\n",
    "plt.plot(x, pdf_fitted, 'g--', linewidth=2)\n",
    "\n",
    "print  param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(l), np.mean(np.absolute(l)), np.max(np.absolute(l)), np.mean(Data['power'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For bin reference\n",
    "numbins = int(math.ceil(np.max(d['V-s'])/0.1))\n",
    "meandifflist = [0]*numbins\n",
    "maxdifflist = [0]*numbins\n",
    "middlebinvalue = [0.1*i+0.05 for i in range(0,numbins)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data.to_csv(dataDir +'/data_with_full_forecast.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
