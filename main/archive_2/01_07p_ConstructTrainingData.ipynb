{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data investigation, we would like to construct training data with things we have learned from data investigation. Let's pull up all information and data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#specify data source, zipcode (along with latitude, longitue, and timezone), and bin values to calculate mean.\n",
    "datasource = 'L'\n",
    "#[zipcode, latitude, longitude, localtz] = ['08640', 40.0039, -74.6178, 'US/Eastern']\n",
    "#[zipcode, latitude, longitude, localtz] = ['08641', 40.0449, -74.5892, 'US/Eastern']\n",
    "#this vin values serves only NJ \n",
    "#binvalue = [0.60000000000000009, 1.5531428571428569, 2.5209606741573034, 4.1015736906211933, 7.487476098503139, 12.943637931034482]\n",
    "#[zipcode, latitude, longitude, localtz] = ['92562', 33.5686, -117.2530, 'US/Pacific']\n",
    "[zipcode, latitude, longitude, localtz] = ['92563', 33.5712, -117.1540, 'US/Pacific']\n",
    "#this bin values serves only CA\n",
    "binvalue = [0.6366666666666666, 1.5599424405242481, 2.4851360650682972, 3.9649782737139554, 6.7641328892898853, 12.809405655777667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "import patsy #for spline regression\n",
    "import scipy #for non-negative least square \n",
    "import scipy as sp \n",
    "from scipy import stats\n",
    "from scipy.optimize import nnls\n",
    "from numpy.linalg import inv #for matrix and statistics\n",
    "import scipy as sp\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mainDir = 'C:/Users/Tee/Dropbox/Active/EnergyProject/Thesis/PVreadingsStudies/main'\n",
    "mainDir = 'C:\\Users\\Admin\\Dropbox\\Active\\EnergyProject\\Thesis'\n",
    "#read data and metadata\n",
    "metadata = pd.read_csv(mainDir+ '/data/solar/' + datasource +'/' + zipcode +'/metadata.csv',\n",
    "                             dtype={'componentId':'object','zip':'object'})\n",
    "data = pd.read_csv(mainDir+ '/data/solar/' + datasource +'/'+ zipcode+'/data.csv',\n",
    "                             dtype={'componentId':'object'})\n",
    "#convert timestamp string to datetime format if needed\n",
    "#metadata['FirstTimestamp'] = metadata['FirstTimestamp'].map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "#data['tsLocal'] = data['tsLocal'].map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#size assignment according to buckets\n",
    "metadata['size'] = float('NaN')\n",
    "metadata.loc[metadata.sizeBucket == '0-1 kW','size'] = binvalue[0]\n",
    "metadata.loc[metadata.sizeBucket == '1-2 kW','size'] = binvalue[1]\n",
    "metadata.loc[metadata.sizeBucket == '2-3 kW','size'] = binvalue[2]\n",
    "metadata.loc[metadata.sizeBucket == '3-5 kW','size'] = binvalue[3]\n",
    "metadata.loc[metadata.sizeBucket == '5-10 kW','size'] = binvalue[4]\n",
    "metadata.loc[metadata.sizeBucket == '10-20 kW','size'] = binvalue[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select only residential components\n",
    "metadata = metadata[metadata['size'] <= 20]\n",
    "data = data[['tsLocal','altitude','azimuth']+list(metadata['componentId'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to process data is similar to function data crunch. However, we now impose condition on number of components. At each timestamp, if the number of components that provide power readings are less than 50 components, we report 'NaN' as a value at the timestamp. Otherwise, we use the sum of power readings over total size of components that give the sum as a value at the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "dat = data\n",
    "dat = dat.set_index(['tsLocal','altitude','azimuth'])\n",
    "presencecheck = dat.notnull()\n",
    "dat['numactivecomp'] = presencecheck.sum(axis=1)\n",
    "dat['totalpower'] = dat.sum(axis=1)\n",
    "for i in presencecheck.columns.values:\n",
    "    presencecheck[i] = presencecheck[i]*metadata[metadata.componentId == i]['size'].iloc[0]\n",
    "dat['totalsize'] = presencecheck.sum(axis=1)\n",
    "dat['power'] = dat['totalpower']/dat['totalsize']\n",
    "dat['power'][dat.numactivecomp<50] = float('NaN')\n",
    "dat.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save both processed power readings data and relavent metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = mainDir + '/data/solar/' + datasource +'/' + zipcode\n",
    "metadata.to_csv(directory+\"/training_metadata.csv\",index=False)\n",
    "dat[['tsLocal','altitude','azimuth','power','numactivecomp','totalsize']].to_csv(directory+\"/training_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data for maximum profile validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use NJ data to validate maximum profile by running two set of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#specify data source, zipcode (along with latitude, longitue, and timezone), and bin values to calculate mean.\n",
    "#datasource = 'LocusEnergy'\n",
    "\n",
    "#[zipcode, latitude, longitude, localtz] = ['08641', 40.0449, -74.5892, 'US/Eastern']\n",
    "#this vin values serves only NJ \n",
    "#binvalue = [0.60000000000000009, 1.5531428571428569, 2.5209606741573034, 4.1015736906211933, 7.487476098503139, 12.943637931034482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mainDir = 'C:/Users/Tee/Dropbox/Active/EnergyProject/Thesis/PVreadingsStudies/main'\n",
    "mainDir = 'C:\\Users\\Admin\\Dropbox\\Active\\EnergyProject\\Thesis'\n",
    "#read data and metadata\n",
    "metadata = pd.read_csv(mainDir+ '/data/solar/' + datasource +'/' + zipcode +'/metadata.csv',\n",
    "                             dtype={'componentId':'object','zip':'object'})\n",
    "data = pd.read_csv(mainDir+ '/data/solar/' + datasource +'/'+ zipcode+'/data.csv',\n",
    "                             dtype={'componentId':'object'})\n",
    "#convert timestamp string to datetime format if needed\n",
    "#metadata['FirstTimestamp'] = metadata['FirstTimestamp'].map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "#data['tsLocal'] = data['tsLocal'].map(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#size assignment according to buckets\n",
    "metadata['size'] = float('NaN')\n",
    "metadata.loc[metadata.sizeBucket == '0-1 kW','size'] = binvalue[0]\n",
    "metadata.loc[metadata.sizeBucket == '1-2 kW','size'] = binvalue[1]\n",
    "metadata.loc[metadata.sizeBucket == '2-3 kW','size'] = binvalue[2]\n",
    "metadata.loc[metadata.sizeBucket == '3-5 kW','size'] = binvalue[3]\n",
    "metadata.loc[metadata.sizeBucket == '5-10 kW','size'] = binvalue[4]\n",
    "metadata.loc[metadata.sizeBucket == '10-20 kW','size'] = binvalue[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split metadata file by half to construct training data 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata1 = metadata.loc[::2,:]\n",
    "metadata2 = metadata.loc[1::2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata = metadata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(mainDir+ '/data/solar/' + datasource +'/'+ zipcode+'/data.csv',\n",
    "                             dtype={'componentId':'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#select only residential components\n",
    "metadata = metadata[metadata['size'] <= 20]\n",
    "data = data[['tsLocal','altitude','azimuth']+list(metadata['componentId'])]\n",
    "dat = data\n",
    "dat = dat.set_index(['tsLocal','altitude','azimuth'])\n",
    "presencecheck = dat.notnull()\n",
    "dat['numactivecomp'] = presencecheck.sum(axis=1)\n",
    "dat['totalpower'] = dat.sum(axis=1)\n",
    "for i in presencecheck.columns.values:\n",
    "    presencecheck[i] = presencecheck[i]*metadata[metadata.componentId == i]['size'].iloc[0]\n",
    "dat['totalsize'] = presencecheck.sum(axis=1)\n",
    "dat['power'] = dat['totalpower']/dat['totalsize']\n",
    "dat['power'][dat.numactivecomp<50] = float('NaN')\n",
    "dat.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = mainDir + '/data/solar/' + datasource +'/' + zipcode\n",
    "metadata.to_csv(directory+\"/training_metadata_1.csv\",index=False)\n",
    "dat[['tsLocal','altitude','azimuth','power','numactivecomp','totalsize']].to_csv(directory+\"/training_data_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = metadata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(mainDir+ '/data/solar/' + datasource +'/'+ zipcode+'/data.csv',\n",
    "                             dtype={'componentId':'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#select only residential components\n",
    "metadata = metadata[metadata['size'] <= 20]\n",
    "data = data[['tsLocal','altitude','azimuth']+list(metadata['componentId'])]\n",
    "dat = data\n",
    "dat = dat.set_index(['tsLocal','altitude','azimuth'])\n",
    "presencecheck = dat.notnull()\n",
    "dat['numactivecomp'] = presencecheck.sum(axis=1)\n",
    "dat['totalpower'] = dat.sum(axis=1)\n",
    "for i in presencecheck.columns.values:\n",
    "    presencecheck[i] = presencecheck[i]*metadata[metadata.componentId == i]['size'].iloc[0]\n",
    "dat['totalsize'] = presencecheck.sum(axis=1)\n",
    "dat['power'] = dat['totalpower']/dat['totalsize']\n",
    "dat['power'][dat.numactivecomp<50] = float('NaN')\n",
    "dat.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = mainDir + '/data/solar/' + datasource +'/' + zipcode\n",
    "metadata.to_csv(directory+\"/training_metadata_2.csv\",index=False)\n",
    "dat[['tsLocal','altitude','azimuth','power','numactivecomp','totalsize']].to_csv(directory+\"/training_data_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\Dropbox\\\\Active\\\\EnergyProject\\\\Thesis\\\\PVreadingsStudies\\\\main/data/LocusEnergy/92563'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
